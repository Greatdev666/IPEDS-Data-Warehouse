{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "611933c3",
   "metadata": {},
   "source": [
    "# Installing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "910c7fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas sqlalchemy pyodbc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be66c17",
   "metadata": {},
   "source": [
    "# Create Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8a5359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# -------------------------------\n",
    "# PostgreSQL Connection Settings\n",
    "# -------------------------------\n",
    "user = \"\"          # your pgAdmin username\n",
    "password = \"\" # replace with your PostgreSQL password\n",
    "host = \"localhost\"         # if running locally\n",
    "port = 5432                # default PostgreSQL port\n",
    "database = \"IPEDSDataWarehouse\"      # the DB you created in pgAdmin\n",
    "\n",
    "# -------------------------------\n",
    "# SQLAlchemy Connection String\n",
    "# -------------------------------\n",
    "connection_string = f\"postgresql+psycopg2://{user}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "# -------------------------------\n",
    "# Create Engine\n",
    "# -------------------------------\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "print(\"‚úÖ Connected successfully to PostgreSQL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8205b9a9",
   "metadata": {},
   "source": [
    "# Set Base Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16897168",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = r'C:\\Users\\3D\\OneDrive\\Desktop\\IPEDS Final'\n",
    "file_paths = glob.glob(os.path.join(base_folder, \"**\", \"*.csv\"), recursive=True)\n",
    "\n",
    "print(f\"üìÇ Found {len(file_paths)} CSV files to process\")  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4826d0",
   "metadata": {},
   "source": [
    "# Previewing a few paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f52fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in file_paths:\n",
    "    print(\"‚û°Ô∏è\", f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d815ce7",
   "metadata": {},
   "source": [
    "# Creating All Tables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc3a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "\n",
    "for file_path in file_paths:\n",
    "    table_name = os.path.basename(file_path).replace('.csv','').replace('.', '_').replace('-', '_').lower()\n",
    "    \n",
    "    # Detect encoding from first 100 KB\n",
    "    with open(file_path, 'rb') as f:\n",
    "        rawdata = f.read(100000)\n",
    "        detected = chardet.detect(rawdata)\n",
    "        encoding = detected['encoding'] if detected['encoding'] not in [None, 'ascii'] else 'latin1'\n",
    "\n",
    "    # Read only header safely\n",
    "    df_sample = pd.read_csv(file_path, nrows=0, encoding=encoding)\n",
    "\n",
    "    # Create table in SQL Server\n",
    "    df_sample.to_sql(\n",
    "        name=table_name,\n",
    "        con=engine,\n",
    "        schema='Bronze',\n",
    "        if_exists='replace',\n",
    "        index=False\n",
    "    )\n",
    "    print(f\"‚úÖ Table created: {table_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91afbe0b",
   "metadata": {},
   "source": [
    "# Checking Total Tables Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1b8673",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Connect using psycopg2\n",
    "conn = psycopg2.connect(\n",
    "    dbname='IPEDSDataWarehouse',\n",
    "    user='',\n",
    "    password='',\n",
    "    host='localhost',\n",
    "    port='5432'\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Count tables in the 'bronze' schema\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM information_schema.tables\n",
    "    WHERE table_schema = 'Bronze'\n",
    "\"\"\")\n",
    "table_count = cursor.fetchone()[0]\n",
    "print(f\"‚úÖ Total tables in Bronze schema: {table_count}\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca59b50b",
   "metadata": {},
   "source": [
    "# Bulk Inserting into all Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08221c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "conn = engine.raw_connection()  # raw connection for COPY\n",
    "cursor = conn.cursor()\n",
    "\n",
    "print(\"‚úÖ Connected successfully to PostgreSQL\")\n",
    "\n",
    "# =============================================\n",
    "# 2Ô∏è‚É£ Logging setup\n",
    "# =============================================\n",
    "log_file = \"PostgreSQL_Bronze_load_log_pg_resumable.txt\"\n",
    "success_count = 0\n",
    "failure_count = 0\n",
    "if os.path.exists(log_file):\n",
    "    os.remove(log_file)\n",
    "\n",
    "# =============================================\n",
    "# 3Ô∏è‚É£ Get existing tables in Bronze schema\n",
    "# =============================================\n",
    "cursor.execute(\"\"\"\n",
    "    SELECT table_name \n",
    "    FROM information_schema.tables \n",
    "    WHERE table_schema='Bronze'\n",
    "\"\"\")\n",
    "tables_loaded = [row[0] for row in cursor.fetchall()]\n",
    "print(f\"Tables already in Bronze schema: {len(tables_loaded)}\")\n",
    "\n",
    "# =============================================\n",
    "# 4Ô∏è‚É£ Loop through CSVs and COPY into PostgreSQL\n",
    "# =============================================\n",
    "for i, file_path in enumerate(file_paths, 1):\n",
    "    # PostgreSQL prefers lowercase table names, we convert CSV names\n",
    "    table_name = os.path.basename(file_path).replace('.csv','').replace('.', '_').replace('-', '_').lower()\n",
    "    \n",
    "    # Full table reference with proper schema case\n",
    "    full_table_name = f'\"Bronze\".\"{table_name}\"'\n",
    "\n",
    "    # Check if table exists\n",
    "    if table_name in tables_loaded:\n",
    "        try:\n",
    "            cursor.execute(f'SELECT COUNT(*) FROM {full_table_name}')\n",
    "            rows_loaded = cursor.fetchone()[0]\n",
    "        except Exception:\n",
    "            rows_loaded = 0\n",
    "    else:\n",
    "        print(f\"[{i}/{len(file_paths)}] ‚ö†Ô∏è Table {table_name} does not exist in schema Bronze, skipping\")\n",
    "        failure_count += 1\n",
    "        with open(log_file, \"a\", encoding=\"utf-8\") as f_log:\n",
    "            f_log.write(f\"‚ùå FAILED: {file_path} -> Table does not exist\\n\")\n",
    "        continue\n",
    "\n",
    "    # Count total rows in CSV (skip header)\n",
    "    try:\n",
    "        total_rows = sum(1 for _ in open(file_path, 'r', encoding='utf-8', errors='ignore')) - 1\n",
    "    except Exception as e:\n",
    "        failure_count += 1\n",
    "        with open(log_file, \"a\", encoding=\"utf-8\") as f_log:\n",
    "            f_log.write(f\"‚ùå FAILED: {file_path} -> {e}\\n\")\n",
    "        print(f\"‚ùå FAILED: {table_name} -> {e}\")\n",
    "        continue\n",
    "\n",
    "    # Skip fully loaded tables\n",
    "    if rows_loaded >= total_rows:\n",
    "        print(f\"[{i}/{len(file_paths)}] ‚è≠ Skipping {table_name} (already fully loaded)\")\n",
    "        continue\n",
    "    elif rows_loaded > 0:\n",
    "        print(f\"[{i}/{len(file_paths)}] ‚ö° Resuming {table_name} from row {rows_loaded + 2}...\")\n",
    "\n",
    "        # Create temp CSV with remaining rows\n",
    "        temp_file = tempfile.NamedTemporaryFile(delete=False, mode='w', newline='', encoding='utf-8')\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            for j, line in enumerate(f):\n",
    "                if j > rows_loaded:\n",
    "                    temp_file.write(line)\n",
    "        temp_file.close()\n",
    "        bulk_file_path = temp_file.name\n",
    "    else:\n",
    "        print(f\"[{i}/{len(file_paths)}] üöÄ Loading {table_name} ...\")\n",
    "        bulk_file_path = file_path\n",
    "\n",
    "    # COPY into PostgreSQL\n",
    "    try:\n",
    "        with open(bulk_file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            cursor.copy_expert(f'COPY {full_table_name} FROM STDIN WITH CSV HEADER', f)\n",
    "        conn.commit()\n",
    "\n",
    "        success_count += 1\n",
    "        with open(log_file, \"a\", encoding=\"utf-8\") as f_log:\n",
    "            f_log.write(f\"‚úÖ SUCCESS: {table_name}\\n\")\n",
    "\n",
    "        print(f\"‚úÖ Loaded {table_name}\")\n",
    "\n",
    "        # Remove temporary file if used\n",
    "        if rows_loaded > 0:\n",
    "            os.remove(temp_file.name)\n",
    "\n",
    "    except Exception as e:\n",
    "        failure_count += 1\n",
    "        conn.rollback()\n",
    "        with open(log_file, \"a\", encoding=\"utf-8\") as f_log:\n",
    "            f_log.write(f\"‚ùå FAILED: {file_path} -> {e}\\n\")\n",
    "        print(f\"‚ùå FAILED: {table_name} -> {e}\")\n",
    "\n",
    "# =============================================\n",
    "# 5Ô∏è‚É£ Summary\n",
    "# =============================================\n",
    "print(\"\\nüéâ Bronze Layer Ingestion Complete!\")\n",
    "print(f\"‚úÖ Successful files: {success_count}\")\n",
    "print(f\"‚ùå Failed files: {failure_count}\")\n",
    "print(f\"üìÑ Full log: {log_file}\")\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
